{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, nbrs=5):\n",
    "        self.nbrs = nbrs\n",
    "\n",
    "    def fit(self, X_t, y_t):\n",
    "        self.X_t = X_t.to_numpy()\n",
    "        self.y_t = y_t.to_numpy()\n",
    "\n",
    "    def dists(self, X_p):\n",
    "        t = np.dot(X_p, self.X_t.transpose())\n",
    "        dists = np.sqrt(-2 * t + np.square(self.X_t).sum(1) + np.matrix(np.square(X_p).sum(1)).T)\n",
    "        return dists\n",
    "\n",
    "    def predict(self, X_p):\n",
    "        dists = self.dists(X_p.to_numpy())\n",
    "        preds = np.zeros(dists.shape[0])\n",
    "        for i in range(dists.shape[0]):\n",
    "            labels = self.y_t[np.argsort(dists[i,:])].flatten()\n",
    "            top_nn_y = labels[:self.nbrs]\n",
    "            preds[i] = Counter(top_nn_y).most_common(1)[0][0]\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBC():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_t, y_t):\n",
    "        X_t = X_t.to_numpy()\n",
    "        y_t = y_t.to_numpy()\n",
    "        self.num_of_classes = np.max(y_t) + 1\n",
    "        self.priorities = np.bincount(y_t) / len(y_t)\n",
    "        self.Ms = np.array([X_t[np.where(y_t == i)].mean(axis=0) for i in range(self.num_of_classes)])\n",
    "        self.stds = np.array([X_t[np.where(y_t == i)].std(axis=0) for i in range(self.num_of_classes)])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_p):\n",
    "        X_p = X_p.to_numpy()\n",
    "        res = []\n",
    "        for i in range(len(X_p)):\n",
    "            Ps = []\n",
    "            for j in range(self.num_of_classes):\n",
    "                Ps.append((1 / np.sqrt(2 * np.pi * self.stds[j]**2) * np.exp(-0.5*((X_p[i] - self.Ms[j]) / self.stds[j])**2)).prod() * self.priorities[j])\n",
    "            Ps = np.array(Ps)\n",
    "            res.append(Ps / Ps.sum())\n",
    "        return np.array(res).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR():\n",
    "    def __init__(self, lr=0.01, steps=5000):\n",
    "        self.lr = lr\n",
    "        self.steps = steps\n",
    "\n",
    "    def s(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        self.coefs = np.zeros(X.shape[1])\n",
    "\n",
    "        for _ in range(self.steps):\n",
    "            h = self.s(np.dot(X, self.coefs))\n",
    "            self.coefs -= self.lr * \\\n",
    "                          np.dot(X.T, (h - y)) / y.size\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        return self.s(np.dot(X, self.coefs)).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_feature(a):\n",
    "    a_extended = np.zeros((a.shape[0],a.shape[1]+1))\n",
    "    a_extended[:,:-1] = a\n",
    "    a_extended[:,-1] = int(1)  \n",
    "    return a_extended\n",
    "\n",
    "class SVM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, etha=0.01, alpha=0.1, epochs=200):\n",
    "        self._epochs = epochs\n",
    "        self._etha = etha\n",
    "        self._alpha = alpha\n",
    "        self._w = None\n",
    "        self.history_w = []\n",
    "        self.train_errors = None\n",
    "        self.val_errors = None\n",
    "        self.train_loss = None\n",
    "        self.val_loss = None\n",
    "\n",
    "    def fit(self, X_train, Y_train, X_val, Y_val, verbose=False):\n",
    "        X_train, Y_train, X_val, Y_val = X_train.to_numpy(), Y_train.to_numpy(), X_val.to_numpy(), Y_val.to_numpy()\n",
    "\n",
    "\n",
    "        if len(set(Y_train)) != 2 or len(set(Y_val)) != 2:\n",
    "            raise ValueError(\"Number of classes in Y is not equal 2!\")\n",
    "\n",
    "        X_train = add_bias_feature(X_train)\n",
    "        X_val = add_bias_feature(X_val)\n",
    "        self._w = np.random.normal(loc=0, scale=0.05, size=X_train.shape[1])\n",
    "        #self.history_w.append(self._w)\n",
    "        np.append(self.history_w, self._w)\n",
    "        train_errors = []\n",
    "        val_errors = []\n",
    "        train_loss_epoch = []\n",
    "        val_loss_epoch = []\n",
    "\n",
    "        for epoch in range(self._epochs): \n",
    "            tr_err = 0\n",
    "            val_err = 0\n",
    "            tr_loss = 0\n",
    "            val_loss = 0\n",
    "            for i,x in enumerate(X_train):\n",
    "                margin = Y_train[i]*np.dot(self._w,X_train[i])\n",
    "                if margin >= 1:\n",
    "                    self._w = self._w - self._etha*self._alpha*self._w/self._epochs\n",
    "                    tr_loss += self.soft_margin_loss(X_train[i],Y_train[i])\n",
    "                else:\n",
    "                    self._w = self._w +\\\n",
    "                    self._etha*(Y_train[i]*X_train[i] - self._alpha*self._w/self._epochs)\n",
    "                    tr_err += 1\n",
    "                    tr_loss += self.soft_margin_loss(X_train[i],Y_train[i])\n",
    "                #self.history_w.append(self._w)\n",
    "                np.append(self.history_w, self._w)\n",
    "            for i,x in enumerate(X_val):\n",
    "                val_loss += self.soft_margin_loss(X_val[i], Y_val[i])\n",
    "                val_err += (Y_val[i]*np.dot(self._w,X_val[i])<1).astype(int)\n",
    "            train_errors.append(tr_err)\n",
    "            val_errors.append(val_err)\n",
    "            train_loss_epoch.append(tr_loss)\n",
    "            val_loss_epoch.append(val_loss)\n",
    "        self.history_w = np.array(self.history_w)    \n",
    "        self.train_errors = np.array(train_errors)\n",
    "        self.val_errors = np.array(val_errors)\n",
    "        self.train_loss = np.array(train_loss_epoch)\n",
    "        self.val_loss = np.array(val_loss_epoch)                    \n",
    "\n",
    "    def predict(self, X:np.array) -> np.array:\n",
    "        y_pred = []\n",
    "        X_extended = add_bias_feature(X)\n",
    "        for i in range(len(X_extended)):\n",
    "            y_pred.append(np.sign(np.dot(self._w,X_extended[i])))\n",
    "        return np.array(y_pred)         \n",
    "\n",
    "    def hinge_loss(self, x, y):\n",
    "        return max(0,1 - y*np.dot(x, self._w))\n",
    "\n",
    "    def soft_margin_loss(self, x, y):\n",
    "        return self.hinge_loss(x,y)+self._alpha*np.dot(self._w, self._w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "labelencoder=LabelEncoder()\n",
    "for column in df.columns:\n",
    "    df[column] = labelencoder.fit_transform(df[column])\n",
    "X = df.drop([' salary'], axis=1)\n",
    "y = df[' salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model, X, y, k_folds=5):\n",
    "    kf = KFold(n_splits=k_folds, random_state=16, shuffle=True)\n",
    "    scores = np.zeros(k_folds)\n",
    "    precisions = np.zeros(k_folds)    \n",
    "    recalls = np.zeros(k_folds)    \n",
    "    for i, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "        X_train, y_train = X.loc[train_index], y.loc[train_index]\n",
    "        X_test, y_test = X.loc[val_index], y.loc[val_index]\n",
    "        if isinstance(model, SVM):\n",
    "           model.fit(X_train, y_train, X_test, y_test)\n",
    "           y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        #model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        confusions = confusion_matrix(y_test, y_pred)\n",
    "        scores[i] = accuracy_score(y_test, y_pred)\n",
    "        precisions[i] = precision_score(y_test, y_pred)\n",
    "        recalls[i] = recall_score(y_test, y_pred)\n",
    "        print(\"Confusion matrix:\\n\", confusions, \"\\n\")\n",
    "        print(\"Acuracy score: {}\".format(scores[i]))\n",
    "        print(\"Precision score: {}\".format(precisions[i]))\n",
    "        print(\"Recall score: {}\\n\".format(recalls[i]))\n",
    "    return (scores, precisions, recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модели и получаем оценки метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1082   34]\n",
      " [1004   50]] \n",
      "\n",
      "Acuracy score: 0.5216589861751152\n",
      "Precision score: 0.5952380952380952\n",
      "Recall score: 0.04743833017077799\n",
      "\n",
      "Confusion matrix:\n",
      " [[   0 1112]\n",
      " [   0 1058]] \n",
      "\n",
      "Acuracy score: 0.4875576036866359\n",
      "Precision score: 0.4875576036866359\n",
      "Recall score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      " [[1112   17]\n",
      " [1007   34]] \n",
      "\n",
      "Acuracy score: 0.528110599078341\n",
      "Precision score: 0.6666666666666666\n",
      "Recall score: 0.03266090297790586\n",
      "\n",
      "Confusion matrix:\n",
      " [[428 673]\n",
      " [142 926]] \n",
      "\n",
      "Acuracy score: 0.6242508068234209\n",
      "Precision score: 0.5791119449656035\n",
      "Recall score: 0.8670411985018727\n",
      "\n",
      "Confusion matrix:\n",
      " [[1141   17]\n",
      " [ 975   36]] \n",
      "\n",
      "Acuracy score: 0.5426463808206546\n",
      "Precision score: 0.6792452830188679\n",
      "Recall score: 0.03560830860534125\n",
      "\n",
      "Accuracy:  0.5408448753168335\n",
      "Precision:  0.6015639187151738\n",
      "Recall:  0.39654974805117954\n",
      "CPU times: user 30.8 s, sys: 1min 11s, total: 1min 42s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LR()\n",
    "metrics = pipeline(lr, X, y)\n",
    "print(\"Accuracy: \", metrics[0].mean())\n",
    "print(\"Precision: \", metrics[1].mean())\n",
    "print(\"Recall: \", metrics[2].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[743 373]\n",
      " [358 696]] \n",
      "\n",
      "Acuracy score: 0.6631336405529954\n",
      "Precision score: 0.6510757717492984\n",
      "Recall score: 0.6603415559772297\n",
      "\n",
      "Confusion matrix:\n",
      " [[743 369]\n",
      " [350 708]] \n",
      "\n",
      "Acuracy score: 0.6686635944700461\n",
      "Precision score: 0.6573816155988857\n",
      "Recall score: 0.6691871455576559\n",
      "\n",
      "Confusion matrix:\n",
      " [[695 434]\n",
      " [333 708]] \n",
      "\n",
      "Acuracy score: 0.6465437788018433\n",
      "Precision score: 0.6199649737302977\n",
      "Recall score: 0.6801152737752162\n",
      "\n",
      "Confusion matrix:\n",
      " [[727 374]\n",
      " [374 694]] \n",
      "\n",
      "Acuracy score: 0.6551406177962195\n",
      "Precision score: 0.649812734082397\n",
      "Recall score: 0.649812734082397\n",
      "\n",
      "Confusion matrix:\n",
      " [[755 403]\n",
      " [308 703]] \n",
      "\n",
      "Acuracy score: 0.6721991701244814\n",
      "Precision score: 0.635623869801085\n",
      "Recall score: 0.695351137487636\n",
      "\n",
      "Accuracy:  0.661136160349117\n",
      "Precision:  0.6427717929923927\n",
      "Recall:  0.6709615693760269\n",
      "CPU times: user 13.9 s, sys: 1.13 s, total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "knn = KNN()\n",
    "metrics = pipeline(knn, X, y)\n",
    "print(\"Accuracy: \", metrics[0].mean())\n",
    "print(\"Precision: \", metrics[1].mean())\n",
    "print(\"Recall: \", metrics[2].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[   0 1116]\n",
      " [   0 1054]] \n",
      "\n",
      "Acuracy score: 0.4857142857142857\n",
      "Precision score: 0.4857142857142857\n",
      "Recall score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      " [[   0 1112]\n",
      " [   0 1058]] \n",
      "\n",
      "Acuracy score: 0.4875576036866359\n",
      "Precision score: 0.4875576036866359\n",
      "Recall score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      " [[   0 1129]\n",
      " [   0 1041]] \n",
      "\n",
      "Acuracy score: 0.47972350230414745\n",
      "Precision score: 0.47972350230414745\n",
      "Recall score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      " [[   0 1101]\n",
      " [   0 1068]] \n",
      "\n",
      "Acuracy score: 0.49239280774550487\n",
      "Precision score: 0.49239280774550487\n",
      "Recall score: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      " [[   0 1158]\n",
      " [   0 1011]] \n",
      "\n",
      "Acuracy score: 0.4661134163208852\n",
      "Precision score: 0.4661134163208852\n",
      "Recall score: 1.0\n",
      "\n",
      "Accuracy:  0.48230032315429183\n",
      "Precision:  0.48230032315429183\n",
      "Recall:  1.0\n",
      "CPU times: user 2min 4s, sys: 0 ns, total: 2min 4s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm = SVM()\n",
    "metrics = pipeline(svm, X, y)\n",
    "print(\"Accuracy: \", metrics[0].mean())\n",
    "print(\"Precision: \", metrics[1].mean())\n",
    "print(\"Recall: \", metrics[2].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[966 150]\n",
      " [376 678]] \n",
      "\n",
      "Acuracy score: 0.7576036866359447\n",
      "Precision score: 0.8188405797101449\n",
      "Recall score: 0.6432637571157496\n",
      "\n",
      "Confusion matrix:\n",
      " [[965 147]\n",
      " [386 672]] \n",
      "\n",
      "Acuracy score: 0.7543778801843318\n",
      "Precision score: 0.8205128205128205\n",
      "Recall score: 0.6351606805293005\n",
      "\n",
      "Confusion matrix:\n",
      " [[992 137]\n",
      " [373 668]] \n",
      "\n",
      "Acuracy score: 0.7649769585253456\n",
      "Precision score: 0.8298136645962733\n",
      "Recall score: 0.6416906820365034\n",
      "\n",
      "Confusion matrix:\n",
      " [[948 153]\n",
      " [360 708]] \n",
      "\n",
      "Acuracy score: 0.7634854771784232\n",
      "Precision score: 0.8222996515679443\n",
      "Recall score: 0.6629213483146067\n",
      "\n",
      "Confusion matrix:\n",
      " [[995 163]\n",
      " [331 680]] \n",
      "\n",
      "Acuracy score: 0.7722452743199631\n",
      "Precision score: 0.8066429418742586\n",
      "Recall score: 0.6726013847675568\n",
      "\n",
      "Accuracy:  0.7625378553688017\n",
      "Precision:  0.8196219316522881\n",
      "Recall:  0.6511275705527434\n",
      "CPU times: user 594 ms, sys: 24 ms, total: 618 ms\n",
      "Wall time: 597 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nbc = NBC()\n",
    "metrics = pipeline(nbc, X, y)\n",
    "print(\"Accuracy: \", metrics[0].mean())\n",
    "print(\"Precision: \", metrics[1].mean())\n",
    "print(\"Recall: \", metrics[2].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коробочные решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 73.95 %\n",
      "Standard Deviation: 1.23 %\n",
      "\n",
      "KNN Classifier\n",
      "Accuracy: 65.94 %\n",
      "Standard Deviation: 1.64 %\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Accuracy: 76.12 %\n",
      "Standard Deviation: 0.76 %\n",
      "\n",
      "SVM Classifier\n",
      "Accuracy: 74.00 %\n",
      "Standard Deviation: 10.20 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def LoRtrainer(X,y,final = False):\n",
    "    print('Logistic Regression')\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier = LogisticRegression(max_iter=1000)\n",
    "    classifier.fit(X,y)\n",
    "    if final:\n",
    "        return classifier\n",
    "    else:\n",
    "        accuracies = cross_val_score(estimator = classifier, X = X, y = y, cv = 10)\n",
    "        print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "        print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "        print('')\n",
    "        \n",
    "def KNNtrainer(X,y,final = False):\n",
    "    print('KNN Classifier')\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X,y)\n",
    "    if final:\n",
    "        return classifier\n",
    "    else:\n",
    "        accuracies = cross_val_score(estimator = classifier, X = X, y = y, cv = 10)\n",
    "        print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "        print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "        print('')\n",
    "\n",
    "def NBCtrainer(X,y,final = False):\n",
    "    print('Naive Bayes Classifier')\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X,y)\n",
    "    if final:\n",
    "        return classifier\n",
    "    else:\n",
    "        accuracies = cross_val_score(estimator = classifier, X = X, y = y, cv = 10)\n",
    "        print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "        print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "        print('')\n",
    "\n",
    "def SVCtrainer(X,y,final = False):\n",
    "    print('SVM Classifier')\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'linear')\n",
    "    classifier.fit(X,y)\n",
    "    if final:\n",
    "         return classifier\n",
    "    else:\n",
    "        accuracies = cross_val_score(estimator = classifier, X = X, y = y, cv = 10)\n",
    "        print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "        print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "        \n",
    "def TestAll(X,y):\n",
    "    LoRtrainer(X,y)\n",
    "    KNNtrainer(X[: 7000],y[: 7000])\n",
    "    NBCtrainer(X,y)\n",
    "    SVCtrainer(X[: 100],y[: 100])\n",
    "\n",
    "TestAll(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"my_models.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lr, f)\n",
    "    pickle.dump(knn, f)\n",
    "    pickle.dump(svm, f)\n",
    "    pickle.dump(nbc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод\n",
    " В результате проделанной лабораторной были реализованы методы LR, SVM, KNN, Naive Bayes. По результатам проделанной реботы можно сделать вывод, что для данного набора данных лучше всего подходит Naive Bayes, который дает точность около 82%. Следует заметить, что метод SVM обучается очень долго на данной выборке, поэтому было сильно уменьшено количество входных данных. Точность построенных моделей примерно совпадает с коробочными решениями."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('my-conda-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bb41bf90696e22c87001632e65500875ddba9442ddbb5b4702107e5972aba08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
